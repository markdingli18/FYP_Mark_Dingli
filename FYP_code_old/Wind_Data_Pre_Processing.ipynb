{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983ab358",
   "metadata": {},
   "source": [
    "# NetCDF File Processing\n",
    "\n",
    "This notebook details the process for preprocessing and interpolating a NetCDF file across specified start and end dates. The resulting file will include concatenated data along the time dimension, interpolated to specified geographical points and hourly intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d53279",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a773b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8064b",
   "metadata": {},
   "source": [
    "### Data Selection\n",
    "\n",
    "Selecting the relevant date range and geographical points for the data processing. The goal is to interpolate the dataset to these specific points and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c703598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end dates\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-01-03'\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('Data/Wind/data.nc')\n",
    "\n",
    "# Define the time range for interpolation\n",
    "end_date_extended = pd.Timestamp(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)\n",
    "times_hourly = pd.date_range(start=start_date, end=end_date_extended, freq='h')\n",
    "\n",
    "# Define the specific longitude and latitude points for interpolation (to match the sea surface current data)\n",
    "longitude_points = np.array([13.6768, 13.7174, 13.7579, 13.7985, 13.839, 13.8796, 13.9202, 13.9607, 14.0013,\n",
    "                             14.0419, 14.0824, 14.123, 14.1635, 14.2041, 14.2447, 14.2852, 14.3258, 14.3664,\n",
    "                             14.4069, 14.4475, 14.488, 14.5286, 14.5692, 14.6097, 14.6503, 14.6908, 14.7314,\n",
    "                             14.772, 14.8125, 14.8531, 14.8937, 14.9342, 14.9748, 15.0153, 15.0559, 15.0965,\n",
    "                             15.137, 15.1776, 15.2182, 15.2587, 15.2993, 15.3398, 15.3804])\n",
    "latitude_points = np.array([35.7447, 35.767, 35.7892, 35.8115, 35.8338, 35.856, 35.8783, 35.9006, 35.9228,\n",
    "                            35.9451, 35.9673, 35.9896, 36.0119, 36.0341, 36.0564, 36.0787, 36.1009, 36.1232,\n",
    "                            36.1455, 36.1677, 36.19, 36.2123, 36.2345, 36.2568, 36.2791, 36.3013, 36.3236,\n",
    "                            36.3458, 36.3681, 36.3904, 36.4126, 36.4349, 36.4572, 36.4794, 36.5017, 36.524,\n",
    "                            36.5462, 36.5685, 36.5908, 36.613, 36.6353, 36.6576, 36.6798, 36.7021, 36.7243,\n",
    "                            36.7466, 36.7689, 36.7911, 36.8134, 36.8357, 36.8579, 36.8802])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fadc31",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "\n",
    "Linearly interpolate the dataset to the defined hourly time points and geographical coordinates. This step ensures the data matches the desired spatial and temporal resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fad2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform interpolation\n",
    "ds_interpolated = ds.interp(\n",
    "    time=times_hourly,\n",
    "    longitude=longitude_points,\n",
    "    latitude=latitude_points,\n",
    "    method='linear'\n",
    ")\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = \"Data/Processed_Wind_Data.nc\"\n",
    "\n",
    "# Save the interpolated dataset to a new file\n",
    "ds_interpolated.to_netcdf(output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996598c",
   "metadata": {},
   "source": [
    "### Verify Merged Dataset\n",
    "\n",
    "This code opens the merged NetCDF file and verifies its contents, ensuring that the dimensions, coordinates, and variables are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0168b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================================================\n",
      "Processed Wind Data Information\n",
      "=============================================================================================================================\n",
      "\n",
      "Dataset Dimensions:\n",
      "FrozenMappingWarningOnValuesAccess({'time': 72, 'latitude': 52, 'longitude': 43})\n",
      "\n",
      "Dataset Coordinates:\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2023-01-01 ... 2023-01-03T23:00:00\n",
      "  * longitude  (longitude) float64 13.68 13.72 13.76 13.8 ... 15.3 15.34 15.38\n",
      "  * latitude   (latitude) float64 35.74 35.77 35.79 35.81 ... 36.84 36.86 36.88\n",
      "\n",
      "Data Variables in the Dataset:\n",
      "Data variables:\n",
      "    v10      (time, latitude, longitude) float64 ...\n",
      "    u10      (time, latitude, longitude) float64 ...\n",
      "\n",
      "Attributes (Metadata) in the Dataset:\n",
      "{'Conventions': 'CF-1.6', 'history': '2023-12-17 08:43:38 GMT by grib_to_netcdf-2.25.1: /opt/ecmwf/mars-client/bin/grib_to_netcdf.bin -S param -o /cache/tmp/77d2d03f-e095-4d90-b83e-999c43b3595c-adaptor.mars_constrained.external-1702802610.7212312-29905-15-tmp.nc /cache/tmp/77d2d03f-e095-4d90-b83e-999c43b3595c-adaptor.mars_constrained.external-1702802608.214588-29905-14-tmp.grib'}\n",
      "Time Points: 72\n",
      "\n",
      "Latitude Range in the Dataset: 35.7447 to 36.8802\n",
      "Longitude Range in the Dataset: 13.6768 to 15.3804\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Open the processed wind dataset\n",
    "ds = xr.open_dataset(output_file_path)\n",
    "\n",
    "# Print dataset information\n",
    "print(\"=\" * 125)\n",
    "print(\"Processed Wind Data Information\")\n",
    "print(\"=\" * 125)\n",
    "print(\"\\nDataset Dimensions:\")\n",
    "print(ds.dims)\n",
    "print(\"\\nDataset Coordinates:\")\n",
    "print(ds.coords)\n",
    "print(\"\\nData Variables in the Dataset:\")\n",
    "print(ds.data_vars)\n",
    "print(\"\\nAttributes (Metadata) in the Dataset:\")\n",
    "print(ds.attrs)\n",
    "\n",
    "# Verify the time dimension is as expected\n",
    "time_points = ds.sizes['time']\n",
    "print(\"Time Points:\", time_points)\n",
    "\n",
    "# Ensure the lat/lon are within the specified bounds\n",
    "lat_min, lat_max = ds['latitude'].min().item(), ds['latitude'].max().item()\n",
    "lon_min, lon_max = ds['longitude'].min().item(), ds['longitude'].max().item()\n",
    "print(\"\\nLatitude Range in the Dataset:\", lat_min, \"to\", lat_max)\n",
    "print(\"Longitude Range in the Dataset:\", lon_min, \"to\", lon_max)\n",
    "\n",
    "# Assert the presence of expected variables\n",
    "assert 'u10' in ds.variables, \"u10 variable is missing from the dataset\"\n",
    "assert 'v10' in ds.variables, \"v10 variable is missing from the dataset\"\n",
    "\n",
    "print(\"=\" * 125)\n",
    "\n",
    "# Close the dataset after inspection\n",
    "ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
